# -*- coding: utf-8 -*-
"""Framework 2: LCGAn Vs baselines.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JYn_iK6AhMczGc5KFIz4kX3Aq1Gwugx1
"""

# Framework 2: LCGAN Vs baseline models

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, re, bz2, shutil, glob, json
from pathlib import Path
import random
import numpy as np
import pandas as pd
import cv2
import dlib
import matplotlib.pyplot as plt

import torch
import torch.nn.functional as F

# Optional
try:
    from skimage.metrics import structural_similarity as ssim
except Exception:
    ssim = None

try:
    from facenet_pytorch import InceptionResnetV1
except Exception:
    InceptionResnetV1 = None

try:
    from scipy.spatial import Delaunay
except Exception:
    Delaunay = None


# =========================
# data path
# =========================
RAFD_IMAGES_DIR = "/content/drive/MyDrive/facial lanadmarks/RAFD dataset/DATASET/train"
RAFD_LABELS_DIR = "/content/drive/MyDrive/facial lanadmarks/RAFD dataset/train_labels.csv"

OUTPUT_ROOT = "./benchmark_outputs"
os.makedirs(OUTPUT_ROOT, exist_ok=True)

PREDICTOR_PATH = "/content/drive/MyDrive/facial lanadmarks/shape_predictor_68_face_landmarks.dat"

SOURCE_EXPR = "happy"
TARGET_EXPR = "sad"

EVAL_MODELS = {
    "Proposed_LCGAN": True,
    "GANimation":     False,
    "X2Face":         False,
    "AttentionGAN":   False,
    "C2GAN":          False,
}

RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# Canonical expression names
CANON_EXPR = {
    "neutral":"neutral",
    "happy":"happy","happiness":"happy",
    "sad":"sad","sadness":"sad",
    "angry":"angry","anger":"angry",
    "fearful":"fearful","fear":"fearful",
    "surprised":"surprised","surprise":"surprised",
    "disgusted":"disgusted","disgust":"disgusted",
    "contemptuous":"contemptuous","contempt":"contemptuous","contemptuousness":"contemptuous",
}

EXPRESSIONS = list({
    "neutral","happy","sad","angry","fearful","surprised","disgusted","contemptuous"
})


# =========================
# IMAGE & LABEL LOADING
# =========================
def scan_images(root: str) -> dict:
    """Return {basename_with_ext: full_path} scanning recursively."""
    exts = ("*.jpg","*.jpeg","*.png","*.bmp","*.tif","*.tiff")
    files = []
    for ext in exts:
        files.extend(glob.glob(os.path.join(root, "**", ext), recursive=True))
    mapping = {}
    for p in files:
        mapping[Path(p).name] = p
    return mapping

def canonicalize_expr(x: str) -> str:
    if not isinstance(x, str):
        return "unknown"
    s = x.strip().lower()
    return CANON_EXPR.get(s, s)

def try_read_csv_labels(labels_dir: str) -> pd.DataFrame:
    """Try reading any CSV in labels_dir that contains filename+expression (and ideally identity)."""
    csvs = glob.glob(os.path.join(labels_dir, "*.csv"))
    best = None
    for p in csvs:
        try:
            df = pd.read_csv(p)
        except Exception:
            continue
        cols = {c.lower(): c for c in df.columns}
        # candidates
        fname_col = next((cols[c] for c in ["filename","file","image","img","img_name","imgpath","path"] if c in cols), None)
        expr_col  = next((cols[c] for c in ["expression","expr","emotion","label","target"] if c in cols), None)
        # identity optional
        id_col    = next((cols[c] for c in ["identity","id","subject","subject_id","person","participant"] if c in cols), None)
        if fname_col and expr_col:
            cur = pd.DataFrame({
                "image": df[fname_col].astype(str).apply(lambda s: Path(s).name),
                "expression": df[expr_col].astype(str).map(canonicalize_expr),
            })
            if id_col:
                cur["identity"] = df[id_col].astype(str)
            best = cur if best is None else pd.concat([best, cur], ignore_index=True)
    return best

def try_read_txt_labels(labels_dir: str) -> pd.DataFrame:
    """Try simple TXT formats: lines like 'filename,expression' or 'filename expression'."""
    txts = glob.glob(os.path.join(labels_dir, "*.txt"))
    if not txts:
        return None
    rows = []
    for p in txts:
        try:
            for line in open(p, "r", encoding="utf-8", errors="ignore"):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "," in line:
                    parts = [t.strip() for t in line.split(",")]
                else:
                    parts = line.split()
                if len(parts) < 2:
                    continue
                fname = Path(parts[0]).name
                expr  = canonicalize_expr(parts[1])
                identity = parts[2] if len(parts) > 2 else None
                rows.append({"image": fname, "expression": expr, "identity": identity})
        except Exception:
            pass
    if not rows:
        return None
    df = pd.DataFrame(rows)
    if "identity" not in df or df["identity"].isna().all():
        df.drop(columns=["identity"], errors="ignore", inplace=True)
    return df

def infer_expr_from_name(name: str) -> str:
    n = name.lower()
    for e in EXPRESSIONS:
        if e in n:
            return e
    # fallback via canonical dict keys
    for raw, can in CANON_EXPR.items():
        if raw in n:
            return can
    return "unknown"

def identity_key_from_name(name: str) -> str:
    """Heuristic identity key from filename (when labels lack identity)."""
    base = Path(name).stem.lower()
    # remove known expression tokens
    for e in EXPRESSIONS:
        base = base.replace(f"_{e}", "")
    for raw in CANON_EXPR.keys():
        base = base.replace(f"_{raw}", "")
    # chop trailing camera/lighting tokens if present like '_right','_left','_frontal'
    base = re.sub(r"_(left|right|frontal|up|down)$", "", base)
    return base

def load_rafd_labels(images_dir: str, labels_dir: str) -> pd.DataFrame:
    """
    Returns DataFrame with columns: image, expression, identity (if available).
    """
    df = try_read_csv_labels(labels_dir)
    if df is None or df.empty:
        df = try_read_txt_labels(labels_dir)
    if df is None or df.empty:
        # fallback: infer from filename
        files = scan_images(images_dir)
        rows = []
        for fname in files.keys():
            rows.append({
                "image": fname,
                "expression": infer_expr_from_name(fname),
                "identity": identity_key_from_name(fname),
            })
        return pd.DataFrame(rows)
    # ensure identity
    if "identity" not in df.columns:
        df["identity"] = df["image"].map(identity_key_from_name)
    return df



# DLIB / LANDMARKS

def ensure_shape_predictor(dat_or_bz2_path: str) -> dlib.shape_predictor:
    p = dat_or_bz2_path
    if not os.path.exists(p):
        alt = p + ".bz2" if not p.endswith(".bz2") else p[:-4]
        if os.path.exists(alt): p = alt
    if not os.path.exists(p):
        raise FileNotFoundError(f"Predictor not found: {dat_or_bz2_path}")
    if p.endswith(".bz2"):
        out_dat = p[:-4]
        if not os.path.exists(out_dat):
            print(f"Decompressing {p} -> {out_dat} ...")
            with bz2.open(p, "rb") as fi, open(out_dat, "wb") as fo:
                shutil.copyfileobj(fi, fo)
        p = out_dat
    if os.path.getsize(p) < 50_000_000:
        raise RuntimeError("Predictor file too small; re-download 68-pt model.")
    return dlib.shape_predictor(p)

PREDICTOR = ensure_shape_predictor(PREDICTOR_PATH)
DETECTOR  = dlib.get_frontal_face_detector()

def shape_to_np(shape: dlib.full_object_detection) -> np.ndarray:
    pts = np.zeros((shape.num_parts, 2), dtype=np.float32)
    for i in range(shape.num_parts):
        pts[i] = (shape.part(i).x, shape.part(i).y)
    return pts

def detect_68_landmarks(bgr: np.ndarray):
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    rects = DETECTOR(gray, 1)
    if not rects:
        return None
    rect = max(rects, key=lambda r: r.width()*r.height())
    shape = PREDICTOR(gray, rect)
    if shape.num_parts != 68:
        return None
    return shape_to_np(shape)

def inter_ocular_distance(landmarks):
    right_eye_idx = list(range(36,42))
    left_eye_idx  = list(range(42,48))
    cr = landmarks[right_eye_idx].mean(axis=0)
    cl = landmarks[left_eye_idx].mean(axis=0)
    return float(np.linalg.norm(cr - cl))



# PROPOSED LCGAN

def one_based_pair(a,b): return (a-1, b-1)

S1_pairs_1b = [(38,42), (39,41)]
S2_pairs_1b = [(44,48), (45,47)]
S3_pairs_1b = [(50,61), (54,65), (62,68), (63,67), (64,66)]
S4_pairs_1b = [(50,60), (51,59), (52,58), (53,57), (54,56)]
S1 = [one_based_pair(*p) for p in S1_pairs_1b]
S2 = [one_based_pair(*p) for p in S2_pairs_1b]
S3 = [one_based_pair(*p) for p in S3_pairs_1b]
S4 = [one_based_pair(*p) for p in S4_pairs_1b]

FACTORS_SAD = {
    "d1": 0.95, "d2": 0.95,
    "d3": 0.95, "d4": 0.95,
    "d5": 0.65, "d6": 0.65, "d7": 0.65, "d8": 0.65, "d9": 0.65,
    "d10": 0.85, "d11": 0.85, "d12": 0.85, "d13": 0.85, "d14": 0.85,
}

def triangle_area(tri):
    a = tri[1] - tri[0]; b = tri[2] - tri[0]
    return 0.5 * abs(a[0]*b[1] - a[1]*b[0])

def delaunay_triangles(pts):
    pts = np.asarray(pts, dtype=np.float64)
    if Delaunay is not None:
        tri = Delaunay(pts)
        return tri.simplices
    # Fallback: OpenCV Subdiv2D
    h = int(np.max(pts[:,1])+2); w = int(np.max(pts[:,0])+2)
    subdiv = cv2.Subdiv2D((0,0,w,h))
    for (x,y) in pts:
        subdiv.insert((float(x), float(y)))
    triangle_list = subdiv.getTriangleList()
    triangles = []
    for t in triangle_list:
        pts_tri = np.array([[t[0], t[1]],[t[2], t[3]],[t[4], t[5]]], dtype=np.float32)
        idxs = []
        for v in pts_tri:
            d = np.sum((pts - v)**2, axis=1)
            idxs.append(int(np.argmin(d)))
        if len(set(idxs)) == 3:
            triangles.append(idxs)
    return np.array(triangles, dtype=np.int32)

def triangle_warp(img, src_pts, dst_pts, triangles):
    h, w = img.shape[:2]
    out = np.zeros_like(img)
    for simplex in triangles:
        src_tri = np.asarray(src_pts[simplex], dtype=np.float32)
        dst_tri = np.asarray(dst_pts[simplex], dtype=np.float32)
        if triangle_area(src_tri) < 1e-3 or triangle_area(dst_tri) < 1e-3:
            continue
        x1, y1, w1, h1 = cv2.boundingRect(src_tri)
        x2, y2, w2, h2 = cv2.boundingRect(dst_tri)
        if min(w1,h1,w2,h2) < 1:
            continue
        src_off = (src_tri - np.array([[x1,y1]], dtype=np.float32)).reshape(3,2)
        dst_off = (dst_tri - np.array([[x2,y2]], dtype=np.float32)).reshape(3,2)
        M = cv2.getAffineTransform(src_off, dst_off)
        patch = img[y1:y1+h1, x1:x1+w1]
        warped = cv2.warpAffine(patch, M, (w2,h2), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)
        mask = np.zeros((h2,w2), dtype=np.uint8)
        cv2.fillConvexPoly(mask, np.int32(dst_off), 255)
        roi = out[y2:y2+h2, x2:x2+w2]
        warped_masked = cv2.bitwise_and(warped, warped, mask=mask)
        bg = cv2.bitwise_and(roi, roi, mask=cv2.bitwise_not(mask))
        out[y2:y2+h2, x2:x2+w2] = cv2.add(bg, warped_masked)
    # Fill holes
    holes = (out == 0).all(axis=2)
    out[holes] = img[holes]
    return out

def accumulate_displacements(n):
    return np.zeros((n,2), dtype=np.float32), np.zeros(n, dtype=np.float32)

def shrink_pair(pts, i, j, factor, disp_sum, disp_w):
    factor = float(factor)
    if factor >= 0.999: return
    vi = pts[i].copy(); vj = pts[j].copy()
    vec = vj - vi; d = np.linalg.norm(vec)
    if d < 1e-6: return
    pull = 0.5 * (1.0 - factor) * d
    dir_ = vec / d
    disp_sum[i] += +pull * dir_; disp_w[i] += 1.0
    disp_sum[j] += -pull * dir_; disp_w[j] += 1.0

def apply_displacements(pts, disp_sum, disp_w):
    out = pts.copy(); nz = disp_w > 0
    out[nz] = pts[nz] + (disp_sum[nz] / disp_w[nz, None])
    return out

def proposed_lcgan_edit(src_bgr: np.ndarray, target_expr: str="sad") -> np.ndarray:
    pts = detect_68_landmarks(src_bgr)
    if pts is None:
        return None

    factors = FACTORS_SAD.copy() if target_expr == "sad" else FACTORS_SAD.copy()

    disp_sum, disp_w = accumulate_displacements(68)
    names_S1 = ["d1","d2"]; names_S2 = ["d3","d4"]
    names_S3 = ["d5","d6","d7","d8","d9"]; names_S4 = ["d10","d11","d12","d13","d14"]

    for (pairs, names) in [(S1,names_S1),(S2,names_S2),(S3,names_S3),(S4,names_S4)]:
        for (i,j), nm in zip(pairs, names):
            shrink_pair(pts, i, j, factors[nm], disp_sum, disp_w)

    tgt = apply_displacements(pts, disp_sum, disp_w)

    # extra sad cue: pull down mouth corners slightly
    down = 0.06 * inter_ocular_distance(pts)
    for corner_idx in (48, 54):
        tgt[corner_idx, 1] += down

    tri = delaunay_triangles(pts)
    warped = triangle_warp(src_bgr, pts.astype(np.float32), tgt.astype(np.float32), tri)
    return warped


# METRICS

def compute_ssim(a_bgr, b_bgr):
    if ssim is None:
        return np.nan
    a = cv2.cvtColor(a_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0
    b = cv2.cvtColor(b_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0
    return float(ssim(a, b, data_range=1.0))

def compute_ncc(a_bgr, b_bgr):
    a = cv2.cvtColor(a_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    b = cv2.cvtColor(b_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)
    a = (a - a.mean()) / (a.std() + 1e-8)
    b = (b - b.mean()) / (b.std() + 1e-8)
    return float((a * b).mean())

def compute_landmark_metrics(gen_bgr, tgt_bgr):
    gen_lmk = detect_68_landmarks(gen_bgr)
    tgt_lmk = detect_68_landmarks(tgt_bgr)
    if gen_lmk is None or tgt_lmk is None:
        return np.nan, np.nan
    diffs = np.linalg.norm(gen_lmk - tgt_lmk, axis=1)
    aed = float(diffs.mean())
    nme = float(diffs.mean() / (inter_ocular_distance(tgt_lmk) + 1e-8))
    return aed, nme

class FaceEmbedder:
    def __init__(self, device="cuda" if torch.cuda.is_available() else "cpu"):
        self.device = device
        self.model = None if InceptionResnetV1 is None else InceptionResnetV1(pretrained="vggface2").eval().to(self.device)

    def __call__(self, bgr: np.ndarray):
        if self.model is None:
            return None
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        img = cv2.resize(rgb, (160,160), interpolation=cv2.INTER_AREA)
        t = torch.tensor(img).float().permute(2,0,1)[None] / 255.0
        mean = torch.tensor([0.5,0.5,0.5])[None,:,None,None]
        std  = torch.tensor([0.5,0.5,0.5])[None,:,None,None]
        t = (t - mean) / std
        t = t.to(self.device)
        with torch.no_grad():
            emb = self.model(t)
        v = F.normalize(emb, dim=1).cpu().numpy()[0]
        return v

def cosine_sim(a, b):
    if a is None or b is None:
        return np.nan
    return float(np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b) + 1e-8))

EMBEDDER = FaceEmbedder()



# MODEL functions

class ModelRunner:
    name = "Base"
    def generate(self, src_bgr: np.ndarray, target_expr: str, src_path: str, tgt_path: str):
        raise NotImplementedError

class ProposedRunner(ModelRunner):
    name = "Proposed_LCGAN"
    def generate(self, src_bgr, target_expr, src_path, tgt_path):
        return proposed_lcgan_edit(src_bgr, target_expr)

class PrecomputedRunner(ModelRunner):
    """Loads precomputed outputs from disk. Adjust path templating as needed."""
    def __init__(self, model_name, outputs_dir="./precomputed"):
        self.name = model_name
        self.outputs_dir = outputs_dir

    def path_for(self, src_path: str, target_expr: str) -> str:
        id_key = Path(src_path).stem  # adjust if you store differently
        fname = f"{id_key}_to_{target_expr}.png"
        return os.path.join(self.outputs_dir, self.name, fname)

    def generate(self, src_bgr, target_expr, src_path, tgt_path):
        p = self.path_for(src_path, target_expr)
        if os.path.exists(p):
            return cv2.imread(p)
        return None

class GANimationRunner(PrecomputedRunner):
    def __init__(self, outputs_dir="./precomputed"): super().__init__("GANimation", outputs_dir)
class X2FaceRunner(PrecomputedRunner):
    def __init__(self, outputs_dir="./precomputed"): super().__init__("X2Face", outputs_dir)
class AttentionGANRunner(PrecomputedRunner):
    def __init__(self, outputs_dir="./precomputed"): super().__init__("AttentionGAN", outputs_dir)
class C2GANRunner(PrecomputedRunner):
    def __init__(self, outputs_dir="./precomputed"): super().__init__("C2GAN", outputs_dir)



def build_pairs_from_labels(images_dir: str, labels_dir: str, src_expr: str, tgt_expr: str, max_pairs=None):
    # 1) images map
    img_map = scan_images(images_dir)  # {basename: fullpath}

    # 2) labels
    df = load_rafd_labels(images_dir, labels_dir)
    df["expression"] = df["expression"].map(canonicalize_expr)
    df = df[df["expression"].isin(EXPRESSIONS)].copy()

    # Attach full path and drop any rows whose image file isn't found
    df["image_path"] = df["image"].map(img_map.get)
    df = df[~df["image_path"].isna()].copy()

    # 3) pivot per identity → have both src and tgt
    # ensure identity exists
    if "identity" not in df.columns:
        df["identity"] = df["image"].map(identity_key_from_name)

    # Two views: source and target rows
    src_df = df[df["expression"] == canonicalize_expr(src_expr)][["identity","image_path"]].rename(columns={"image_path":"src_path"})
    tgt_df = df[df["expression"] == canonicalize_expr(tgt_expr)][["identity","image_path"]].rename(columns={"image_path":"tgt_path"})

    merged = pd.merge(src_df, tgt_df, on="identity", how="inner").drop_duplicates()
    pairs = list(merged[["src_path","tgt_path"]].itertuples(index=False, name=None))

    if max_pairs is not None:
        pairs = pairs[:max_pairs]

    return pairs  # list of (src_path, tgt_path)



# EVALUATION

def evaluate(models, pairs, out_csv=os.path.join(OUTPUT_ROOT, "benchmark_results.csv")):
    rows = []
    for src_path, tgt_path in pairs:
        src_bgr = cv2.imread(src_path)
        tgt_bgr = cv2.imread(tgt_path)
        if src_bgr is None or tgt_bgr is None:
            continue

        src_emb = EMBEDDER(src_bgr)

        for runner in models:
            gen_bgr = runner.generate(src_bgr, TARGET_EXPR, src_path, tgt_path)
            if gen_bgr is None:
                continue

            # Resize generated to target dims for pixelwise metrics
            if gen_bgr.shape[:2] != tgt_bgr.shape[:2]:
                gen_bgr = cv2.resize(gen_bgr, (tgt_bgr.shape[1], tgt_bgr.shape[0]), interpolation=cv2.INTER_AREA)

            m_ssim = compute_ssim(gen_bgr, tgt_bgr)
            m_ncc  = compute_ncc(gen_bgr, tgt_bgr)
            m_aed, m_lmk = compute_landmark_metrics(gen_bgr, tgt_bgr)
            gen_emb = EMBEDDER(gen_bgr)
            m_id   = cosine_sim(src_emb, gen_emb)

            rows.append({
                "model": runner.name,
                "src": Path(src_path).name,
                "tgt": Path(tgt_path).name,
                "SSIM": m_ssim,
                "NCC": m_ncc,
                "AED_px": m_aed,
                "LMK_NME": m_lmk,
                "ID_cos": m_id,
            })

    df = pd.DataFrame(rows)
    df.to_csv(out_csv, index=False)
    print(f"Saved per-sample results to: {out_csv}")
    return df

def summarize(df: pd.DataFrame, out_csv=os.path.join(OUTPUT_ROOT, "benchmark_summary.csv")):
    agg = df.groupby("model").agg(["mean","std"])
    agg.columns = [f"{a}_{b}" for a,b in agg.columns]
    agg = agg.reset_index()
    agg.to_csv(out_csv, index=False)
    print(f"Saved summary to: {out_csv}")
    return agg

def plot_bars(agg: pd.DataFrame, metrics=("SSIM","NCC","ID_cos","AED_px","LMK_NME")):
    for m in metrics:
        m_mean = f"{m}_mean"; m_std = f"{m}_std"
        if m_mean not in agg.columns:
            continue
        x = np.arange(len(agg))
        vals = agg[m_mean].values
        errs = agg[m_std].values
        plt.figure(figsize=(7,4))
        plt.bar(x, vals, yerr=errs, capsize=4)
        plt.xticks(x, agg["model"].tolist(), rotation=20)
        plt.ylabel(m)
        plt.title(f"{m} (mean ± std)")
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_ROOT, f"bar_{m}.png"), dpi=200)
        plt.close()
    print(f"Saved bar charts in: {OUTPUT_ROOT}")

def main():
    pairs = build_pairs_from_labels(RAFD_IMAGES_DIR, RAFD_LABELS_DIR, SOURCE_EXPR, TARGET_EXPR, max_pairs=None)
    print(f"Found {len(pairs)} identity pairs for {SOURCE_EXPR} → {TARGET_EXPR}")

    runners = []
    if EVAL_MODELS.get("Proposed_LCGAN", False):
        runners.append(ProposedRunner())
    if EVAL_MODELS.get("GANimation", False):
        runners.append(GANimationRunner())
    if EVAL_MODELS.get("X2Face", False):
        runners.append(X2FaceRunner())
    if EVAL_MODELS.get("AttentionGAN", False):
        runners.append(AttentionGANRunner())
    if EVAL_MODELS.get("C2GAN", False):
        runners.append(C2GANRunner())

    if not runners:
        print("No models enabled. Toggle EVAL_MODELS flags.")
        return

    df = evaluate(runners, pairs, out_csv=os.path.join(OUTPUT_ROOT, "benchmark_results.csv"))
    if df.empty:
        print("No results to summarize (did any model generate outputs?).")
        return
    agg = summarize(df, out_csv=os.path.join(OUTPUT_ROOT, "benchmark_summary.csv"))
    plot_bars(agg)

if __name__ == "__main__":
    main()