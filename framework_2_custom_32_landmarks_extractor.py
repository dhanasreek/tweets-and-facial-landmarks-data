# -*- coding: utf-8 -*-
"""Framework 2: custom 32 landmarks extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JYn_iK6AhMczGc5KFIz4kX3Aq1Gwugx1
"""

# Custom 32 landmarks extraction from an image

import os, bz2, shutil, dlib

def ensure_shape_predictor(dat_or_bz2_path: str) -> dlib.shape_predictor:
    """
    - Accepts .dat or .dat.bz2
    - If .bz2, decompresses to sibling .dat
    - Checks size (~99 MB) to catch corrupt files
    - Returns a loaded dlib.shape_predictor
    """
    p = dat_or_bz2_path
    if not os.path.exists(p):
        # if user gave .dat but only .bz2 exists, try that
        alt = p + ".bz2" if not p.endswith(".bz2") else p[:-4]
        if os.path.exists(alt): p = alt
    if not os.path.exists(p):
        raise FileNotFoundError(f"Predictor not found: {dat_or_bz2_path}")

    # Decompress if needed
    if p.endswith(".bz2"):
        out_dat = p[:-4]
        if not os.path.exists(out_dat):
            print(f"Decompressing {p} -> {out_dat} ...")
            with bz2.open(p, "rb") as f_in, open(out_dat, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)
        p = out_dat

    # Size sanity check (official 68-pt file is ~99 MB)
    sz = os.path.getsize(p)
    if sz < 50_000_000:   # too small -> almost certainly wrong/corrupt
        raise RuntimeError(
            f"shape_predictor file looks too small ({sz} bytes). "
            "Re-download the official 68-pt model: "
            "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
        )

    try:
        predictor = dlib.shape_predictor(p)
    except RuntimeError as e:
        raise RuntimeError(
            f"Failed to load predictor at {p}. "
            "Likely compressed/corrupted or wrong format. "
            "Re-download the official .bz2 and decompress to .dat. "
            f"Original error: {e}"
        )
    return predictor

import cv2
import numpy as np
import pandas as pd
from pathlib import Path

IMAGE_PATH = "/content/drive/MyDrive/facial lanadmarks/I1.jpg"
# Point to either the .dat OR the .dat.bz2 (this loader handles both):
PREDICTOR_PATH = "/content/drive/MyDrive/facial lanadmarks/shape_predictor_68_face_landmarks.dat.bz2"  # or "...dat.bz2"

detector = dlib.get_frontal_face_detector()
predictor = ensure_shape_predictor(PREDICTOR_PATH)  # <- fixes the RuntimeError

def shape_to_np(shape):
    pts = np.zeros((shape.num_parts, 2), dtype=np.int32)
    for i in range(shape.num_parts):
        pts[i] = (shape.part(i).x, shape.part(i).y)
    return pts

img = cv2.imread(IMAGE_PATH)
if img is None:
    raise FileNotFoundError(IMAGE_PATH)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

rects = detector(gray, 1)
if not rects:
    raise RuntimeError("No face detected.")
rect = max(rects, key=lambda r: r.width()*r.height())

shape = predictor(gray, rect)
if shape.num_parts != 68:
    raise RuntimeError(f"Predictor returned {shape.num_parts} points, expected 68.")

pts68 = shape_to_np(shape)

# --- Save 68 ---
row68 = {f"x_{i}": int(x) for i, (x, y) in enumerate(pts68)}
row68.update({f"y_{i}": int(y) for i, (x, y) in enumerate(pts68)})
row68["image"] = Path(IMAGE_PATH).name
pd.DataFrame([row68]).to_csv("/content/drive/MyDrive/landmarks68_single.csv", index=False)

# --- Save custom 32 (jaw 0–16, eyes 36–41 & 42–47, nose anchors 30,31,35) ---
CUSTOM_32_IDX = list(range(0, 17)) + list(range(36, 42)) + list(range(42, 48)) + [30, 31, 35]
assert len(CUSTOM_32_IDX) == 32

row32 = {}
for idx in CUSTOM_32_IDX:
    x, y = pts68[idx]
    row32[f"x_{idx}"] = int(x)
    row32[f"y_{idx}"] = int(y)
row32["image"] = Path(IMAGE_PATH).name
pd.DataFrame([row32]).to_csv("/content/drive/MyDrive/custom32_face_eyes.csv", index=False)

print("Saved:\n - /content/drive/MyDrive/custom32_face_eyes.csv")



